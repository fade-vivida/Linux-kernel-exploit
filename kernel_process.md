# Kernel Process #
linux kernel 源码版本为 2.6.39.4 以及 5.2，无特殊说明情况下代码为2.6.39版本。


首先回答一个问题：到底什么是进程，什么是线程？进程、线程的区别又是什么？

一篇很好的文章：[https://www.zhihu.com/question/25532384](https://www.zhihu.com/question/25532384)

**注：名词是对客观事物的指代，形容词是对客观事物的描述。这句话对理解 kernel 的很多术语到底是什么意思很有帮助。**

​		个人对进程、线程的理解。一句话，进程就是程序执行的一个**实例**，而线程则是进程的一个**执行流**。也就是说进程和线程都可以理解为对 CPU 运行时间段的一个划分。不同点在于，进程粒度较大，包含了程序运行的各类资源（即我们常说的上下文），内核对进程进行切换时需要保存当前进程的上下文，然后装载待运行进程的上下文，即进程上下文的切换。而线程则是对进程执行流进一步的细粒度的划分，线程可以共享进程的某些资源，从而在线程切换时不用对上下文内容也进行切换（注：这里所说的线程切换指同进程的线程，不同进程间的线程切换还是需要首先切换上下文信息）。

## 1. 进程描述符

​		为了管理进程，内核必须对每个进程所做的事情进行清楚的描述。例如：内核必须知道进程的优先级，它是正在CPU上运行还是因某些事件而被阻塞。因此，我们需要一个结构体来对进程的相关信息进行描述，这个结构就是我们下面将要探讨的进程描述符。

### 1.1 task_struct 结构体

​		进程描述符是一个 **task_struct** 类型的结构体，它的各个字段包含了与一个进程相关的所有信息。

​		一个 task_struct 结构体如下所示（非常大的结构体，参见的代码为5.2版本）：

```c++
struct task_struct {
#ifdef CONFIG_THREAD_INFO_IN_TASK
	/*
	 * For reasons of header soup (see current_thread_info()), this
	 * must be the first element of task_struct.
	 */
	struct thread_info		thread_info;
#endif
	/* -1 unrunnable, 0 runnable, >0 stopped: */
	volatile long			state;

	/*
	 * This begins the randomizable portion of task_struct. Only
	 * scheduling-critical items should be added above here.
	 */
	randomized_struct_fields_start

	void				*stack;
	refcount_t			usage;
	/* Per task flags (PF_*), defined further below: */
	unsigned int			flags;
	unsigned int			ptrace;

#ifdef CONFIG_SMP
	struct llist_node		wake_entry;
	int				on_cpu;
#ifdef CONFIG_THREAD_INFO_IN_TASK
	/* Current CPU: */
	unsigned int			cpu;
#endif
	unsigned int			wakee_flips;
	unsigned long			wakee_flip_decay_ts;
	struct task_struct		*last_wakee;

	/*
	 * recent_used_cpu is initially set as the last CPU used by a task
	 * that wakes affine another task. Waker/wakee relationships can
	 * push tasks around a CPU where each wakeup moves to the next one.
	 * Tracking a recently used CPU allows a quick search for a recently
	 * used CPU that may be idle.
	 */
	int				recent_used_cpu;
	int				wake_cpu;
#endif
	int				on_rq;

	int				prio;
	int				static_prio;
	int				normal_prio;
	unsigned int			rt_priority;

	const struct sched_class	*sched_class;
	struct sched_entity		se;
	struct sched_rt_entity		rt;
#ifdef CONFIG_CGROUP_SCHED
	struct task_group		*sched_task_group;
#endif
	struct sched_dl_entity		dl;

#ifdef CONFIG_PREEMPT_NOTIFIERS
	/* List of struct preempt_notifier: */
	struct hlist_head		preempt_notifiers;
#endif

#ifdef CONFIG_BLK_DEV_IO_TRACE
	unsigned int			btrace_seq;
#endif

	unsigned int			policy;
	int				nr_cpus_allowed;
	cpumask_t			cpus_allowed;

#ifdef CONFIG_PREEMPT_RCU
	int				rcu_read_lock_nesting;
	union rcu_special		rcu_read_unlock_special;
	struct list_head		rcu_node_entry;
	struct rcu_node			*rcu_blocked_node;
#endif /* #ifdef CONFIG_PREEMPT_RCU */

#ifdef CONFIG_TASKS_RCU
	unsigned long			rcu_tasks_nvcsw;
	u8				rcu_tasks_holdout;
	u8				rcu_tasks_idx;
	int				rcu_tasks_idle_cpu;
	struct list_head		rcu_tasks_holdout_list;
#endif /* #ifdef CONFIG_TASKS_RCU */

	struct sched_info		sched_info;

	struct list_head		tasks;
#ifdef CONFIG_SMP
	struct plist_node		pushable_tasks;
	struct rb_node			pushable_dl_tasks;
#endif

	struct mm_struct		*mm;
	struct mm_struct		*active_mm;

	/* Per-thread vma caching: */
	struct vmacache			vmacache;

#ifdef SPLIT_RSS_COUNTING
	struct task_rss_stat		rss_stat;
#endif
	int				exit_state;
	int				exit_code;
	int				exit_signal;
	/* The signal sent when the parent dies: */
	int				pdeath_signal;
	/* JOBCTL_*, siglock protected: */
	unsigned long			jobctl;

	/* Used for emulating ABI behavior of previous Linux versions: */
	unsigned int			personality;

	/* Scheduler bits, serialized by scheduler locks: */
	unsigned			sched_reset_on_fork:1;
	unsigned			sched_contributes_to_load:1;
	unsigned			sched_migrated:1;
	unsigned			sched_remote_wakeup:1;
#ifdef CONFIG_PSI
	unsigned			sched_psi_wake_requeue:1;
#endif

	/* Force alignment to the next boundary: */
	unsigned			:0;

	/* Unserialized, strictly 'current' */

	/* Bit to tell LSMs we're in execve(): */
	unsigned			in_execve:1;
	unsigned			in_iowait:1;
#ifndef TIF_RESTORE_SIGMASK
	unsigned			restore_sigmask:1;
#endif
#ifdef CONFIG_MEMCG
	unsigned			in_user_fault:1;
#endif
#ifdef CONFIG_COMPAT_BRK
	unsigned			brk_randomized:1;
#endif
#ifdef CONFIG_CGROUPS
	/* disallow userland-initiated cgroup migration */
	unsigned			no_cgroup_migration:1;
	/* task is frozen/stopped (used by the cgroup freezer) */
	unsigned			frozen:1;
#endif
#ifdef CONFIG_BLK_CGROUP
	/* to be used once the psi infrastructure lands upstream. */
	unsigned			use_memdelay:1;
#endif

	unsigned long			atomic_flags; /* Flags requiring atomic access. */

	struct restart_block		restart_block;

	pid_t				pid;
	pid_t				tgid;

#ifdef CONFIG_STACKPROTECTOR
	/* Canary value for the -fstack-protector GCC feature: */
	unsigned long			stack_canary;
#endif
	/*
	 * Pointers to the (original) parent process, youngest child, younger sibling,
	 * older sibling, respectively.  (p->father can be replaced with
	 * p->real_parent->pid)
	 */

	/* Real parent process: */
	struct task_struct __rcu	*real_parent;

	/* Recipient of SIGCHLD, wait4() reports: */
	struct task_struct __rcu	*parent;

	/*
	 * Children/sibling form the list of natural children:
	 */
	struct list_head		children;
	struct list_head		sibling;
	struct task_struct		*group_leader;

	/*
	 * 'ptraced' is the list of tasks this task is using ptrace() on.
	 *
	 * This includes both natural children and PTRACE_ATTACH targets.
	 * 'ptrace_entry' is this task's link on the p->parent->ptraced list.
	 */
	struct list_head		ptraced;
	struct list_head		ptrace_entry;

	/* PID/PID hash table linkage. */
	struct pid			*thread_pid;
	struct hlist_node		pid_links[PIDTYPE_MAX];
	struct list_head		thread_group;
	struct list_head		thread_node;

	struct completion		*vfork_done;

	/* CLONE_CHILD_SETTID: */
	int __user			*set_child_tid;

	/* CLONE_CHILD_CLEARTID: */
	int __user			*clear_child_tid;

	u64				utime;
	u64				stime;
#ifdef CONFIG_ARCH_HAS_SCALED_CPUTIME
	u64				utimescaled;
	u64				stimescaled;
#endif
	u64				gtime;
	struct prev_cputime		prev_cputime;
#ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN
	struct vtime			vtime;
#endif

#ifdef CONFIG_NO_HZ_FULL
	atomic_t			tick_dep_mask;
#endif
	/* Context switch counts: */
	unsigned long			nvcsw;
	unsigned long			nivcsw;

	/* Monotonic time in nsecs: */
	u64				start_time;

	/* Boot based time in nsecs: */
	u64				real_start_time;

	/* MM fault and swap info: this can arguably be seen as either mm-specific or thread-specific: */
	unsigned long			min_flt;
	unsigned long			maj_flt;

#ifdef CONFIG_POSIX_TIMERS
	struct task_cputime		cputime_expires;
	struct list_head		cpu_timers[3];
#endif

	/* Process credentials: */

	/* Tracer's credentials at attach: */
	const struct cred __rcu		*ptracer_cred;

	/* Objective and real subjective task credentials (COW): */
	const struct cred __rcu		*real_cred;

	/* Effective (overridable) subjective task credentials (COW): */
	const struct cred __rcu		*cred;

	/*
	 * executable name, excluding path.
	 *
	 * - normally initialized setup_new_exec()
	 * - access it with [gs]et_task_comm()
	 * - lock it with task_lock()
	 */
	char				comm[TASK_COMM_LEN];

	struct nameidata		*nameidata;

#ifdef CONFIG_SYSVIPC
	struct sysv_sem			sysvsem;
	struct sysv_shm			sysvshm;
#endif
#ifdef CONFIG_DETECT_HUNG_TASK
	unsigned long			last_switch_count;
	unsigned long			last_switch_time;
#endif
	/* Filesystem information: */
	struct fs_struct		*fs;

	/* Open file information: */
	struct files_struct		*files;

	/* Namespaces: */
	struct nsproxy			*nsproxy;

	/* Signal handlers: */
	struct signal_struct		*signal;
	struct sighand_struct		*sighand;
	sigset_t			blocked;
	sigset_t			real_blocked;
	/* Restored if set_restore_sigmask() was used: */
	sigset_t			saved_sigmask;
	struct sigpending		pending;
	unsigned long			sas_ss_sp;
	size_t				sas_ss_size;
	unsigned int			sas_ss_flags;

	struct callback_head		*task_works;

#ifdef CONFIG_AUDIT
#ifdef CONFIG_AUDITSYSCALL
	struct audit_context		*audit_context;
#endif
	kuid_t				loginuid;
	unsigned int			sessionid;
#endif
	struct seccomp			seccomp;

	/* Thread group tracking: */
	u32				parent_exec_id;
	u32				self_exec_id;

	/* Protection against (de-)allocation: mm, files, fs, tty, keyrings, mems_allowed, mempolicy: */
	spinlock_t			alloc_lock;

	/* Protection of the PI data structures: */
	raw_spinlock_t			pi_lock;

	struct wake_q_node		wake_q;

#ifdef CONFIG_RT_MUTEXES
	/* PI waiters blocked on a rt_mutex held by this task: */
	struct rb_root_cached		pi_waiters;
	/* Updated under owner's pi_lock and rq lock */
	struct task_struct		*pi_top_task;
	/* Deadlock detection and priority inheritance handling: */
	struct rt_mutex_waiter		*pi_blocked_on;
#endif

#ifdef CONFIG_DEBUG_MUTEXES
	/* Mutex deadlock detection: */
	struct mutex_waiter		*blocked_on;
#endif

#ifdef CONFIG_TRACE_IRQFLAGS
	unsigned int			irq_events;
	unsigned long			hardirq_enable_ip;
	unsigned long			hardirq_disable_ip;
	unsigned int			hardirq_enable_event;
	unsigned int			hardirq_disable_event;
	int				hardirqs_enabled;
	int				hardirq_context;
	unsigned long			softirq_disable_ip;
	unsigned long			softirq_enable_ip;
	unsigned int			softirq_disable_event;
	unsigned int			softirq_enable_event;
	int				softirqs_enabled;
	int				softirq_context;
#endif

#ifdef CONFIG_LOCKDEP
# define MAX_LOCK_DEPTH			48UL
	u64				curr_chain_key;
	int				lockdep_depth;
	unsigned int			lockdep_recursion;
	struct held_lock		held_locks[MAX_LOCK_DEPTH];
#endif

#ifdef CONFIG_UBSAN
	unsigned int			in_ubsan;
#endif

	/* Journalling filesystem info: */
	void				*journal_info;

	/* Stacked block device info: */
	struct bio_list			*bio_list;

#ifdef CONFIG_BLOCK
	/* Stack plugging: */
	struct blk_plug			*plug;
#endif

	/* VM state: */
	struct reclaim_state		*reclaim_state;

	struct backing_dev_info		*backing_dev_info;

	struct io_context		*io_context;

#ifdef CONFIG_COMPACTION
	struct capture_control		*capture_control;
#endif
	/* Ptrace state: */
	unsigned long			ptrace_message;
	kernel_siginfo_t		*last_siginfo;

	struct task_io_accounting	ioac;
#ifdef CONFIG_PSI
	/* Pressure stall state */
	unsigned int			psi_flags;
#endif
#ifdef CONFIG_TASK_XACCT
	/* Accumulated RSS usage: */
	u64				acct_rss_mem1;
	/* Accumulated virtual memory usage: */
	u64				acct_vm_mem1;
	/* stime + utime since last update: */
	u64				acct_timexpd;
#endif
#ifdef CONFIG_CPUSETS
	/* Protected by ->alloc_lock: */
	nodemask_t			mems_allowed;
	/* Seqence number to catch updates: */
	seqcount_t			mems_allowed_seq;
	int				cpuset_mem_spread_rotor;
	int				cpuset_slab_spread_rotor;
#endif
#ifdef CONFIG_CGROUPS
	/* Control Group info protected by css_set_lock: */
	struct css_set __rcu		*cgroups;
	/* cg_list protected by css_set_lock and tsk->alloc_lock: */
	struct list_head		cg_list;
#endif
#ifdef CONFIG_X86_CPU_RESCTRL
	u32				closid;
	u32				rmid;
#endif
#ifdef CONFIG_FUTEX
	struct robust_list_head __user	*robust_list;
#ifdef CONFIG_COMPAT
	struct compat_robust_list_head __user *compat_robust_list;
#endif
	struct list_head		pi_state_list;
	struct futex_pi_state		*pi_state_cache;
#endif
#ifdef CONFIG_PERF_EVENTS
	struct perf_event_context	*perf_event_ctxp[perf_nr_task_contexts];
	struct mutex			perf_event_mutex;
	struct list_head		perf_event_list;
#endif
#ifdef CONFIG_DEBUG_PREEMPT
	unsigned long			preempt_disable_ip;
#endif
#ifdef CONFIG_NUMA
	/* Protected by alloc_lock: */
	struct mempolicy		*mempolicy;
	short				il_prev;
	short				pref_node_fork;
#endif
#ifdef CONFIG_NUMA_BALANCING
	int				numa_scan_seq;
	unsigned int			numa_scan_period;
	unsigned int			numa_scan_period_max;
	int				numa_preferred_nid;
	unsigned long			numa_migrate_retry;
	/* Migration stamp: */
	u64				node_stamp;
	u64				last_task_numa_placement;
	u64				last_sum_exec_runtime;
	struct callback_head		numa_work;

	struct numa_group		*numa_group;

	/*
	 * numa_faults is an array split into four regions:
	 * faults_memory, faults_cpu, faults_memory_buffer, faults_cpu_buffer
	 * in this precise order.
	 *
	 * faults_memory: Exponential decaying average of faults on a per-node
	 * basis. Scheduling placement decisions are made based on these
	 * counts. The values remain static for the duration of a PTE scan.
	 * faults_cpu: Track the nodes the process was running on when a NUMA
	 * hinting fault was incurred.
	 * faults_memory_buffer and faults_cpu_buffer: Record faults per node
	 * during the current scan window. When the scan completes, the counts
	 * in faults_memory and faults_cpu decay and these values are copied.
	 */
	unsigned long			*numa_faults;
	unsigned long			total_numa_faults;

	/*
	 * numa_faults_locality tracks if faults recorded during the last
	 * scan window were remote/local or failed to migrate. The task scan
	 * period is adapted based on the locality of the faults with different
	 * weights depending on whether they were shared or private faults
	 */
	unsigned long			numa_faults_locality[3];

	unsigned long			numa_pages_migrated;
#endif /* CONFIG_NUMA_BALANCING */

#ifdef CONFIG_RSEQ
	struct rseq __user *rseq;
	u32 rseq_sig;
	/*
	 * RmW on rseq_event_mask must be performed atomically
	 * with respect to preemption.
	 */
	unsigned long rseq_event_mask;
#endif

	struct tlbflush_unmap_batch	tlb_ubc;

	struct rcu_head			rcu;

	/* Cache last used pipe for splice(): */
	struct pipe_inode_info		*splice_pipe;

	struct page_frag		task_frag;

#ifdef CONFIG_TASK_DELAY_ACCT
	struct task_delay_info		*delays;
#endif

#ifdef CONFIG_FAULT_INJECTION
	int				make_it_fail;
	unsigned int			fail_nth;
#endif
	/*
	 * When (nr_dirtied >= nr_dirtied_pause), it's time to call
	 * balance_dirty_pages() for a dirty throttling pause:
	 */
	int				nr_dirtied;
	int				nr_dirtied_pause;
	/* Start of a write-and-pause period: */
	unsigned long			dirty_paused_when;

#ifdef CONFIG_LATENCYTOP
	int				latency_record_count;
	struct latency_record		latency_record[LT_SAVECOUNT];
#endif
	/*
	 * Time slack values; these are used to round up poll() and
	 * select() etc timeout values. These are in nanoseconds.
	 */
	u64				timer_slack_ns;
	u64				default_timer_slack_ns;

#ifdef CONFIG_KASAN
	unsigned int			kasan_depth;
#endif

#ifdef CONFIG_FUNCTION_GRAPH_TRACER
	/* Index of current stored address in ret_stack: */
	int				curr_ret_stack;
	int				curr_ret_depth;

	/* Stack of return addresses for return function tracing: */
	struct ftrace_ret_stack		*ret_stack;

	/* Timestamp for last schedule: */
	unsigned long long		ftrace_timestamp;

	/*
	 * Number of functions that haven't been traced
	 * because of depth overrun:
	 */
	atomic_t			trace_overrun;

	/* Pause tracing: */
	atomic_t			tracing_graph_pause;
#endif

#ifdef CONFIG_TRACING
	/* State flags for use by tracers: */
	unsigned long			trace;

	/* Bitmask and counter of trace recursion: */
	unsigned long			trace_recursion;
#endif /* CONFIG_TRACING */

#ifdef CONFIG_KCOV
	/* Coverage collection mode enabled for this task (0 if disabled): */
	unsigned int			kcov_mode;

	/* Size of the kcov_area: */
	unsigned int			kcov_size;

	/* Buffer for coverage collection: */
	void				*kcov_area;

	/* KCOV descriptor wired with this task or NULL: */
	struct kcov			*kcov;
#endif

#ifdef CONFIG_MEMCG
	struct mem_cgroup		*memcg_in_oom;
	gfp_t				memcg_oom_gfp_mask;
	int				memcg_oom_order;

	/* Number of pages to reclaim on returning to userland: */
	unsigned int			memcg_nr_pages_over_high;

	/* Used by memcontrol for targeted memcg charge: */
	struct mem_cgroup		*active_memcg;
#endif

#ifdef CONFIG_BLK_CGROUP
	struct request_queue		*throttle_queue;
#endif

#ifdef CONFIG_UPROBES
	struct uprobe_task		*utask;
#endif
#if defined(CONFIG_BCACHE) || defined(CONFIG_BCACHE_MODULE)
	unsigned int			sequential_io;
	unsigned int			sequential_io_avg;
#endif
#ifdef CONFIG_DEBUG_ATOMIC_SLEEP
	unsigned long			task_state_change;
#endif
	int				pagefault_disabled;
#ifdef CONFIG_MMU
	struct task_struct		*oom_reaper_list;
#endif
#ifdef CONFIG_VMAP_STACK
	struct vm_struct		*stack_vm_area;
#endif
#ifdef CONFIG_THREAD_INFO_IN_TASK
	/* A live task holds one reference: */
	refcount_t			stack_refcount;
#endif
#ifdef CONFIG_LIVEPATCH
	int patch_state;
#endif
#ifdef CONFIG_SECURITY
	/* Used by LSM modules for access restriction: */
	void				*security;
#endif

#ifdef CONFIG_GCC_PLUGIN_STACKLEAK
	unsigned long			lowest_stack;
	unsigned long			prev_lowest_stack;
#endif

	/*
	 * New fields for task_struct should be added above here, so that
	 * they are included in the randomized portion of task_struct.
	 */
	randomized_struct_fields_end

	/* CPU-specific state of this task: */
	struct thread_struct		thread;

	/*
	 * WARNING: on x86, 'thread_struct' contains a variable-sized
	 * structure.  It *MUST* be at the end of 'task_struct'.
	 *
	 * Do not put anything below here!
	 */
};
```

​		其中我们主要关心一下几个字段。

###  1.2 state 字段

​		该字段描述了进程当前所处的状态。它由一组标志组成，其中每个标志描述一种可能的进程状态。

​		一般来说这些标志互斥（即只能设置为以下值中的一个），sched.h头文件中定义如下：

- TASK_RUNNING（0x00）：进程正在运行

- TASK_INTERRUPTIBLE（0x01）：进程处于等待状态，可中断。也就是说一个中断或者异常事件可以唤醒该进程

- TASK_UNINTERRUPTIBLE（0x02）：进程处于等待状态，不可中断。必须等到某事件结束

- __TASK_STOPPED（0x4）：进程终止

- __TASK_TRACED（0x8）：进程的执行已经被调试器暂停

  还有一些不太常用的如下所示：

```c++
#define TASK_PARKED			0x0040
#define TASK_DEAD			0x0080
#define TASK_WAKEKILL			0x0100
#define TASK_WAKING			0x0200
#define TASK_NOLOAD			0x0400
#define TASK_NEW			0x0800
#define TASK_STATE_MAX			0x1000
```

### 1.3 thread_info 字段

​		该字段为一个 thread_info 类型的结构体，定义了一些与线程相关的信息，因此也被称作线程描述符。其结构体如下所示（2.6.34版本，一个疑问为什么在x86架构下找不到该结构体的定义？）：

```c++
// powerpc/include/asm/thread_info.h
struct thread_info {
	struct task_struct *task;		/* main task structure */
	struct exec_domain *exec_domain;	/* execution domain */
	int		cpu;			/* cpu we're on */
	int		preempt_count;		/* 0 => preemptable,
						   <0 => BUG */
	struct restart_block restart_block;
	unsigned long	local_flags;		/* private flags for thread */

	/* low level flags - has atomic operations done on it */
	unsigned long	flags ____cacheline_aligned_in_smp;
};
```

​		我们可以看到 thread_info 的第一个字段 task 为一个指向其进程描述符（task_struct 结构体）的指针。即我们既可以通过 task_struct->thread_info 找到该进程的 thread_info 结构，同时也能通过 thread_info->task 找到该进程的进程描述符。

​		那么在实际运用中，内核更多是通过 task_struct 找 thread_info 呢，还是通过 thread_info 去找 task_struct？其实，通常使用较多的是通过进程标识符 PID 找到对应的进程描述符 task_struct，然后再获取其 线程描述符 thread_info，具体方法参见第三小节。

​		另一方面，我们知道 CPU 运行的实体为粒度更小的线程，那么有没有什么方法能够快速得到当前线程的 thread_info，然后再通过其得到对应进程的描述符呢？

​		答案是可以，内核通过一个 thread_union 的联合体，将线程描述符与内核态进程堆栈紧凑地存放在一个单独为进程分配的空间（大小为 8192 字节，2个页框），并让第一个页框的地址是 2^13 的倍数。在分析研究 Linux 内核态的分段机制时，我们已经知道内核态的进程访问内核数据段，这个栈不同于用户态所用的栈。因为内核的控制路径使用较少的栈空间（函数栈调用深度远低于用户态），因此只需要几千个字节的内核态堆栈。所以对于栈和 thread_info 结构来说，8KB足够了。

```c++
// version 2.6.34
union thread_union {
	struct thread_info thread_info;
	unsigned long stack[THREAD_SIZE/sizeof(long)];
};

// version 5.2
union thread_union {
#ifndef CONFIG_ARCH_TASK_STRUCT_ON_STACK
	struct task_struct task;
#endif
#ifndef CONFIG_THREAD_INFO_IN_TASK
	struct thread_info thread_info;
#endif
	unsigned long stack[THREAD_SIZE/sizeof(long)];
};
```

​		我们可以看到在 5.2 版本，thread_union 联合体中还多了一个 task_struct 结构体（取决于是否添加编译选项 CONFIG_ARCH_TASK_STRUCT_ON_STACK）。

​		linux内核页定义了 get_current 宏来实现快速通过 thread_info 得到进程描述符结构 task_struct。

```c++
#define get_current() (current_thread_info()->task)
#define current get_current()
```



## 2. 进程链表 ##

### 2.1 init_task 变量 ###
​		进程链表是把所有进程描述符都链接起来的一个双向链表。每个 task\_struct 结构都包含一个 list\_head 类型的 task 字段，这个类型的 prev 和 next 字段分别指向前面和后面的 task\_struct 元素。

​		这里就有一个问题，既然是双向链表那么就应该有一个头结点。这个头结点就是 init\_task 描述符（init\_task 代表所谓的 0 号进程（process 0）或者也可以叫做 swapper 进程）。我们先来看看 kernel 是如何对 init\_task 进行初始化的。

```c++
// init_task.c
struct task_struct init_task = INIT_TASK(init_task);
EXPORT_SYMBOL(init_task);
```
​		kernel 调用 INIT\_TASK宏对 init\_task 全局变量进行初始化。

```c++
// init_task.h
/*
 *  INIT_TASK is used to set up the first task table, touch at
 * your own risk!. Base=0, limit=0x1fffff (=2MB)
 */
#define INIT_TASK(tsk)	\
{									\
	.state		= 0,						\
	.stack		= &init_thread_info,				\
	.usage		= ATOMIC_INIT(2),				\
	.flags		= PF_KTHREAD,					\
	.lock_depth	= -1,						\
	.prio		= MAX_PRIO-20,					\
	.static_prio	= MAX_PRIO-20,					\
	.normal_prio	= MAX_PRIO-20,					\
	.policy		= SCHED_NORMAL,					\
	.cpus_allowed	= CPU_MASK_ALL,					\
	.mm		= NULL,						\
	.active_mm	= &init_mm,					\
	.se		= {						\
		.group_node 	= LIST_HEAD_INIT(tsk.se.group_node),	\
	},								\
	.rt		= {						\
		.run_list	= LIST_HEAD_INIT(tsk.rt.run_list),	\
		.time_slice	= HZ, 					\
		.nr_cpus_allowed = NR_CPUS,				\
	},								\
	.tasks		= LIST_HEAD_INIT(tsk.tasks),			\
	INIT_PUSHABLE_TASKS(tsk)					\
	.ptraced	= LIST_HEAD_INIT(tsk.ptraced),			\
	.ptrace_entry	= LIST_HEAD_INIT(tsk.ptrace_entry),		\
	.real_parent	= &tsk,						\
	.parent		= &tsk,						\
	.children	= LIST_HEAD_INIT(tsk.children),			\
	.sibling	= LIST_HEAD_INIT(tsk.sibling),			\
	.group_leader	= &tsk,						\
	RCU_INIT_POINTER(.real_cred, &init_cred),			\
	RCU_INIT_POINTER(.cred, &init_cred),				\
	.comm		= "swapper",					\
	.thread		= INIT_THREAD,					\
	.fs		= &init_fs,					\
	.files		= &init_files,					\
	.signal		= &init_signals,				\
	.sighand	= &init_sighand,				\
	.nsproxy	= &init_nsproxy,				\
	.pending	= {						\
		.list = LIST_HEAD_INIT(tsk.pending.list),		\
		.signal = {{0}}},					\
	.blocked	= {{0}},					\
	.alloc_lock	= __SPIN_LOCK_UNLOCKED(tsk.alloc_lock),		\
	.journal_info	= NULL,						\
	.cpu_timers	= INIT_CPU_TIMERS(tsk.cpu_timers),		\
	.fs_excl	= ATOMIC_INIT(0),				\
	.pi_lock	= __RAW_SPIN_LOCK_UNLOCKED(tsk.pi_lock),	\
	.timer_slack_ns = 50000, /* 50 usec default slack */		\
	.pids = {							\
		[PIDTYPE_PID]  = INIT_PID_LINK(PIDTYPE_PID),		\
		[PIDTYPE_PGID] = INIT_PID_LINK(PIDTYPE_PGID),		\
		[PIDTYPE_SID]  = INIT_PID_LINK(PIDTYPE_SID),		\
	},								\
	.thread_group	= LIST_HEAD_INIT(tsk.thread_group),		\
	.dirties = INIT_PROP_LOCAL_SINGLE(dirties),			\
	INIT_IDS							\
	INIT_PERF_EVENTS(tsk)						\
	INIT_TRACE_IRQFLAGS						\
	INIT_LOCKDEP							\
	INIT_FTRACE_GRAPH						\
	INIT_TRACE_RECURSION						\
	INIT_TASK_RCU_PREEMPT(tsk)					\
}
```
### 2.2 list\_head 相关操作 ###
#### 2.2.1 list\_entry ####
​		关于 list\_entry\_xxx 宏的理解。  
​		在 linux kernel 中，双向链表使用 list\_head 类型的结构体来将一个个对象链接起来。假设存在如下所示的结构体：  

```c++
strcut my_struct{
	int a;
	int b;
	......
	list_head list_a
	......
}
```
​		其中 list\_a->next 和 list\_a->prev 均指向了下一个 list\_head 结构体。这里就有一个问题，以上面的结构体为例，我们通过 list\_a 字段找到了下一个同类型元素（my\_struct）的 list\_a 字段，但我们想要的是包含该字段的结构体 my\_struct 的地址，我们怎样通过 list\_a 得到该地址呢？

​		对，答案很简单，减去偏移（即 addr\_my\_struct = addr\_list\_a - offset\_list\_a_)。这其实就是 list\_entry\_xxx（p,t,m） 宏所做的事情，该宏定义需要提供三个参数 p,t,m。其中 p 就为上面所说的某个 my\_struct 实例中 list\_a 的地址，t 为该对象的类型（即 my\_struct），m 为该字段的名称（即 list\_a），可以看出后两个参数就是用来计算偏移所用。

#### 2.2.2 list\_add ####
```c++
// list.h
static inline void list_add(struct list_head *new, struct list_head *head)
{
	__list_add(new, head, head->next);
}
static inline void list_add_tail(struct list_head *new, struct list_head *head)
{
	__list_add(new, head->prev, head);
}
static inline void __list_add(struct list_head *new,
			      struct list_head *prev,
			      struct list_head *next)
{
	next->prev = new;
	new->next = next;
	new->prev = prev;
	prev->next = new;
}
```
​		没什么好说的，双向链表的基本操作，list\_add 将 new 插入 head 之后，list\_add\_tail 将 new 插入 head 之前。
#### 2.2.3 list\_for\_each ####
```c++
// list.h
#define list_for_each(pos, head) \
	for (pos = (head)->next; prefetch(pos->next), pos != (head); \
        	pos = pos->next)
#define list_for_each_entry(pos, head, member)				\
	for (pos = list_entry((head)->next, typeof(*pos), member);	\
	     prefetch(pos->member.next), &pos->member != (head); 	\
	     pos = list_entry(pos->member.next, typeof(*pos), member))
```
​		可以看到，list\_for\_each 用来遍历表头 head 指向的链表，通过 pos 返回 list\_head 结构的指针。而 list\_for\_each\_entry 同样是对 head 指向的链表进行遍历，但 pos 返回的是包含该 member 成员的结构的指针。

​		对进程描述符进行遍历的宏定义如下所示：

```c++
#define next_task(p) \
	list_entry_rcu((p)->tasks.next, struct task_struct, tasks)

#define for_each_process(p) \
	for (p = &init_task ; (p = next_task(p)) != &init_task ; )
```
​		我们发现其实该宏定义与 list\_for\_each\_entry 基本相同。
#### 2.2.4 list\_del ####
```c++
static inline void list_del(struct list_head *entry)
{
	__list_del(entry->prev, entry->next);
	entry->next = LIST_POISON1;
	entry->prev = LIST_POISON2;
}
static inline void __list_del(struct list_head * prev, struct list_head * next)
{
	next->prev = prev;
	prev->next = next;
}
```
#### 2.2.5 list\_empty ####
```c++
static inline int list_empty(const struct list_head *head)
{
	return head->next == head;
}
```

### 2.3 进程链表 ###
#### 2.3.1 tasks 字段 ####
​		tasks 字段用来将所有当前存在的进程链接在以 init\_task 为头的双向链表中。
#### 2.3.2 TASK\_RUNNING 状态的进程链表 ####
​		涉及字段包括：**run\_list，prio，array**  

​		虽然我们仅通过 tasks 字段所指向的双向链表也能找到所有当前正在运行的进程，但开销太大。因此，linux kernel 采用了一种新的调度方法。

​		每个 task\_struct 描述符包含一个 list\_head 类型的字段 run\_list。如果当前进程的优先级等于 k（prio字段，且 0<=k<=139），run\_list 字段就把该进程链入优先权级为 k 的可运行进程链表中。同时，每个 CPU 都有它自己的运行队列，即它自己的进程链表集，其结构为 rt\_prio\_array 结构体。

```c++
#define MAX_RT_PRIO 140
struct rt_prio_array {
	int nr_active；//当前源码中已无该字段
	DECLARE_BITMAP(bitmap, MAX_RT_PRIO+1); /* include 1 bit for delimiter */
	struct list_head queue[MAX_RT_PRIO];
};
```
​		enqueue\_task（p，array）函数把进程描述符插入某个运行队列的链表中，其代码本质上等同于：  

```c++
list_add_tail(&p->run_list,&array->queue[p->prio]);
__set_bit(p->prio,array->bitmap);
array->nr_active++;
p->array = array;
```
​		进程描述符的 prio 字段存放进程的动态优先级，而 array 字段是一个指针，指向当前运行队列的 rt\_prio\_array 数据结构。类似地，dequeue\_task（p，array）函数从运行队列的链表中删除一个进程描述符。
#### 2.3.3 进程间的关系 ####
​		关于进程 0 和进程 1。进程 0 和进程 1 由内核创建，进程 1（init）为所有进程的祖先。描述符中与进程亲属关系相关的字段有： 

- **real\_parent**：指向创建了 P 的进程的描述符，如果 P 的父进程不再存在，则指向进程 1（init）的描述符  
- **parent**：指向 P 当前的父进程，它的值通常与 real\_parent 相同，但偶尔也可以不同，例如：当另一个进程发出监控 P 的 ptrace（）调用请求时
- **children**：链表头部，链表中元素都为 P 创建的子进程
- **sibling**：链表头部，指向兄弟进程链表中的下一个元素或前一个元素的指针，这些兄弟进程的父进程都是 P

sched.h 中 task\_struct 结构体中关于上述 4 个字段的定义如下

```c++
/* pointers to (original) parent process, youngest child, younger sibling,older sibling, respectively.  
	(p->father can be replaced with p->real_parent->pid) */
struct task_struct *real_parent; /* real parent process */
struct task_struct *parent; /* recipient of SIGCHLD, wait4() reports */

// children/sibling forms the list of my natural children

struct list_head children;	/* list of my children */
struct list_head sibling;	/* linkage in my parent's children list */
```

​		还有一些其他的字段是关于进程间非亲属关系的，例如：

- **group\_leader**：P 所在进程组的领头进程描述符

- **signal -> leader\_pid**：P 所在的进程组领头进程的 PID

- **tgid**：P 所在的线程组的领头进程的 PID

- **ptraced**：链表头，指向 P 跟踪的所有进程。包括 P 本身的子进程，以及使用了 ptrace 的进程

- **ptrace\_entry**：指向 P 其父进程的 ptraced 链表（用户 P 被跟踪时）。

  ptraced 与 ptrace\_entry 的区别在于，P->ptraced 字段是用来查找 P 所跟踪的所有子进程（即 P 为发起跟踪的进程）。而 P->ptrace\_entry 则是指向跟踪 P 的进程的 ptraced 字段（即 P 为被跟踪的进程）。

  源代码如下所示：

```c++
struct task_struct *group_leader;	/* threadgroup leader */

pid_t tgid;

/*ptraced is the list of tasks this task is using ptrace on.
This includes both natural children and PTRACE_ATTACH targets.
p->ptrace_entry is p's link on the p->parent->ptraced list.*/

struct list_head ptraced;
struct list_head ptrace_entry;
```
## 3. PID与进程描述符 ##
​		PID，进程标识符是我们平常所用的最多与进程相关的一个结构，例如：使用 kill（）系统调用时等。在进程描述符（task\_struct）中的 pid 字段就保存了当前进程的标识符 PID。
​	
```c++
struct task_struct{
	......
	pid_t pid;
	pid_t tgid;
	......
}
```
​		那么就存在一个问题，内核是如何通过 PID 来找到其所对应的 task\_struct 结构体的呢？

​		通过 init\_task 全局变量进行遍历是一个可行的方案，但对于当前动则成千上完个进程的系统而言，顺序遍历是相当低效的。因此，为了加速查找，Linux kernel 引入了 4 个散列表。
### 3.1 pidhash表及链表 ###

```c++
struct task_struct{
	......
	struct pid_link pids[PIDTYPE_MAX];
	......
}
```

​		pidhash 表的类型主要包括以下 4 中：PIDTYPE_PID，PIDTYPE_TGID，PIDTYPE_PGID，PIDTYPE_SID  

```c++
struct task_struct{
    ......
    struct pid_link pids[PIDTYPE_MAX];
    ......
}
struct pid_link
{
    struct hlist_node node;
    struct pid *pid;
};
struct pid
{
    atomic_t count;
    unsigned int level;
    /* lists of tasks that use this pid */
    struct hlist_head tasks[PIDTYPE_MAX];
    struct rcu_head rcu;
    struct upid numbers[1];
};
```

